{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-70e9263ffb50>\", line 16, in <module>\n",
      "    from tensorflow.contrib import seq2seq\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\__init__.py\", line 77, in <module>\n",
      "    from tensorflow.contrib import rpc\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\rpc\\__init__.py\", line 24, in <module>\n",
      "    from tensorflow.contrib.rpc.python.ops.rpc_op import rpc\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\rpc\\python\\ops\\rpc_op.py\", line 26, in <module>\n",
      "    ops.NotDifferentiable(\"TryRpc\")\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2320, in NotDifferentiable\n",
      "    _gradient_registry.register(None, op_type)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\registry.py\", line 67, in register\n",
      "    stack = traceback.extract_stack()\n",
      "  File \"E:\\Anaconda3\\lib\\traceback.py\", line 207, in extract_stack\n",
      "    stack = StackSummary.extract(walk_stack(f), limit=limit)\n",
      "  File \"E:\\Anaconda3\\lib\\traceback.py\", line 354, in extract\n",
      "    linecache.checkcache(filename)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\compilerop.py\", line 140, in check_linecache_ipython\n",
      "    linecache._checkcache_ori(*args)\n",
      "  File \"E:\\Anaconda3\\lib\\linecache.py\", line 74, in checkcache\n",
      "    stat = os.stat(fullname)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 421, in execute_request\n",
      "    self._abort_queues()\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 636, in _abort_queues\n",
      "    self._abort_queue(stream)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 661, in _abort_queue\n",
      "    poller.poll(50)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\zmq\\sugar\\poll.py\", line 99, in poll\n",
      "    return zmq_poll(self.sockets, timeout=timeout)\n",
      "  File \"zmq/backend/cython/_poll.pyx\", line 123, in zmq.backend.cython._poll.zmq_poll\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "sequence to sequence Model\n",
    "\n",
    "官方文档的意思好像是time_major=True的情况下会快一点\n",
    "https://www.tensorflow.org/tutorials/seq2seq\n",
    "不过现在代码都在time_major=False上\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import layers\n",
    "# from tensorflow.python.util import nest\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.contrib import seq2seq\n",
    "from tensorflow.contrib.seq2seq import BahdanauAttention\n",
    "from tensorflow.contrib.seq2seq import LuongAttention\n",
    "from tensorflow.contrib.seq2seq import AttentionWrapper\n",
    "from tensorflow.contrib.seq2seq import BeamSearchDecoder\n",
    "from tensorflow.contrib.rnn import LSTMCell\n",
    "from tensorflow.contrib.rnn import GRUCell\n",
    "from tensorflow.contrib.rnn import MultiRNNCell\n",
    "from tensorflow.contrib.rnn import DropoutWrapper\n",
    "from tensorflow.contrib.rnn import ResidualWrapper\n",
    "# from tensorflow.contrib.rnn import LSTMStateTuple\n",
    "\n",
    "from word_sequence import WordSequence\n",
    "from data_utils import _get_embed_device\n",
    "\n",
    "\n",
    "class SequenceToSequence(object):\n",
    "    \"\"\"SequenceToSequence Model\n",
    "\n",
    "    基本流程\n",
    "    __init__ 基本参数保存，验证参数合法性\n",
    "        build_model 开始构建整个模型\n",
    "            init_placeholders 初始化一些tensorflow的变量占位符\n",
    "            build_encoder 初始化编码器\n",
    "                build_single_cell\n",
    "                    build_encoder_cell\n",
    "            build_decoder 初始化解码器\n",
    "                build_single_cell\n",
    "                    build_decoder_cell\n",
    "            init_optimizer 如果是在训练模式则初始化优化器\n",
    "    train 训练一个batch的数据\n",
    "    predict 预测一个batch的数据\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,                          \n",
    "                 input_vocab_size,#输入词表大小\n",
    "                 target_vocab_size,#输出词表大小\n",
    "                 batch_size=32,#数据batch的大小\n",
    "                 embedding_size=300,#输入词表与输出词表embedding的维度\n",
    "                 mode='train',#取值为 train 或者 decode，训练模式或者预测模式\n",
    "                 hidden_units=256,#RNN模型的中间层大小，encoder和decoder层相同如果encoder层是bidirectional的话，decoder层是双倍大小\n",
    "                 depth=1,#encoder和decoder的rnn层数\n",
    "                 beam_width=0,#beam_width是beamsearch的超参，用于解码如果大于0则使用beamsearch，小于等于0则不使用\n",
    "                 cell_type='lstm',\n",
    "                 dropout=0.2,\n",
    "                 use_dropout=False,\n",
    "                 use_residual=False,\n",
    "                 optimizer='adam',\n",
    "                 learning_rate=1e-3,\n",
    "                 min_learning_rate=1e-6,\n",
    "                 decay_steps=50000,#衰减步数\n",
    "                 max_gradient_norm=5.0,#梯度正则剪裁的系数\n",
    "                 max_decode_step=None,#最大的解码长度，可以是很大的整数，默认是NoneNone的情况下默认是encoder输入最大长度的 4 倍\n",
    "                 attention_type='Bahdanau',\n",
    "                 bidirectional=False,#encoder 是否为双向\n",
    "                 time_major=False,#是否在“计算过程”中使用时间为主的批量数据\n",
    "                 seed=0,\n",
    "                 parallel_iterations=None,#dynamic_rnn 和 dynamic_decode 的并行数量如果要取得可重复结果，在有dropout的情况下，应该设置为\n",
    "                 share_embedding=False,#如果为True，那么encoder和decoder就会共用一个embedding\n",
    "                 pretrained_embedding=False):#是否使用预训练的embedding\n",
    "        \"\"\"保存参数变量，开始构建整个模型\n",
    "        Args:\n",
    "            input_vocab_size: 输入词表大小\n",
    "            target_vocab_size: 输出词表大小\n",
    "            batch_size: 数据batch的大小\n",
    "            embedding_size, 输入词表与输出词表embedding的维度\n",
    "            mode: 取值为 train 或者 decode，训练模式或者预测模式\n",
    "            hidden_units:\n",
    "                RNN模型的中间层大小，encoder和decoder层相同\n",
    "                如果encoder层是bidirectional的话，decoder层是双倍大小\n",
    "            depth: encoder和decoder的rnn层数\n",
    "            beam_width:\n",
    "                beam_width是beamsearch的超参，用于解码\n",
    "                如果大于0则使用beamsearch，小于等于0则不使用\n",
    "            cell_type: rnn神经元类型，lstm 或者 gru\n",
    "            dropout: dropout比例，取值 [0, 1)\n",
    "            use_dropout: 是否使用dropout\n",
    "            use_residual:# 是否使用residual\n",
    "            optimizer: 优化方法， adam, adadelta, sgd, rmsprop, momentum\n",
    "            learning_rate: 学习率\n",
    "            max_gradient_norm: 梯度正则剪裁的系数\n",
    "            max_decode_step:\n",
    "                最大的解码长度，可以是很大的整数，默认是None\n",
    "                None的情况下默认是encoder输入最大长度的 4 倍\n",
    "            attention_type: 'Bahdanau' or 'Luong' 不同的 attention 类型\n",
    "            bidirectional: encoder 是否为双向\n",
    "            time_major:\n",
    "                是否在“计算过程”中使用时间为主的批量数据\n",
    "                注意，改变这个参数并不要求改变输入数据的格式\n",
    "                输入数据的格式为 [batch_size, time_step] 是一个二维矩阵\n",
    "                time_step是句子长度\n",
    "                经过 embedding 之后，数据会变为\n",
    "                [batch_size, time_step, embedding_size]\n",
    "                这是一个三维矩阵（或者三维张量Tensor）\n",
    "                这样的数据格式是 time_major=False 的\n",
    "                如果设置 time_major=True 的话，在部分计算的时候，会把矩阵转置为\n",
    "                [time_step, batch_size, embedding_size]\n",
    "                也就是 time_step 是第一维，所以叫 time_major\n",
    "                TensorFlow官方文档认为time_major=True会比较快\n",
    "            seed: 一些层间操作的随机数 seed 设置\n",
    "            parallel_iterations:\n",
    "                dynamic_rnn 和 dynamic_decode 的并行数量\n",
    "                如果要取得可重复结果，在有dropout的情况下，应该设置为batch_size\n",
    "            share_embedding:\n",
    "                如果为True，那么encoder和decoder就会公用一个embedding\n",
    "        \"\"\"\n",
    "\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_units = hidden_units\n",
    "        self.depth = depth\n",
    "        self.cell_type = cell_type.lower()\n",
    "        self.use_dropout = use_dropout\n",
    "        self.use_residual = use_residual\n",
    "        self.attention_type = attention_type\n",
    "        self.mode = mode\n",
    "        self.optimizer = optimizer\n",
    "        self.learning_rate = learning_rate\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "        self.decay_steps = decay_steps\n",
    "        self.max_gradient_norm = max_gradient_norm\n",
    "        self.keep_prob = 1.0 - dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        self.seed = seed\n",
    "        self.pretrained_embedding = pretrained_embedding\n",
    "        if isinstance(parallel_iterations, int):\n",
    "            self.parallel_iterations = parallel_iterations\n",
    "        else: # if parallel_iterations is None:\n",
    "            self.parallel_iterations = batch_size\n",
    "        self.time_major = time_major\n",
    "        self.share_embedding = share_embedding\n",
    "\n",
    "        self.initializer = tf.random_uniform_initializer(\n",
    "            -0.05, 0.05, dtype=tf.float32\n",
    "        )\n",
    "        # self.initializer = None\n",
    "\n",
    "        assert self.cell_type in ('gru', 'lstm'), \\\n",
    "            'cell_type 应该是 GRU 或者 LSTM'\n",
    "\n",
    "        if share_embedding:\n",
    "            assert input_vocab_size == target_vocab_size, \\\n",
    "                '如果打开 share_embedding，两个vocab_size必须一样'\n",
    "\n",
    "        assert mode in ('train', 'decode'), \\\n",
    "            'mode 必须是 \"train\" 或 \"decode\" 而不是 \"{}\"'.format(mode)\n",
    "\n",
    "        assert dropout >= 0.0 and dropout < 1.0, '0 <= dropout < 1'\n",
    "\n",
    "        assert attention_type.lower() in ('bahdanau', 'luong'), \\\n",
    "            '''attention_type 必须是 \"bahdanau\" 或 \"luong\" 而不是 \"{}\"\n",
    "            '''.format(attention_type)\n",
    "\n",
    "        assert beam_width < target_vocab_size, \\\n",
    "            'beam_width {} 应该小于 target vocab size {}'.format(\n",
    "                beam_width, target_vocab_size\n",
    "            )\n",
    "\n",
    "        self.keep_prob_placeholder = tf.placeholder(\n",
    "            tf.float32,\n",
    "            shape=[],\n",
    "            name='keep_prob'\n",
    "        )\n",
    "\n",
    "        self.global_step = tf.Variable(\n",
    "            0, trainable=False, name='global_step'\n",
    "        )\n",
    "\n",
    "        self.use_beamsearch_decode = False\n",
    "        self.beam_width = beam_width\n",
    "        self.use_beamsearch_decode = True if self.beam_width > 0 else False\n",
    "        self.max_decode_step = max_decode_step\n",
    "\n",
    "        assert self.optimizer.lower() in \\\n",
    "            ('adadelta', 'adam', 'rmsprop', 'momentum', 'sgd'), \\\n",
    "            'optimizer 必须是下列之一： adadelta, adam, rmsprop, momentum, sgd'\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "\n",
    "    def build_model(self):#build_model 开始构建整个模型\n",
    "        \"\"\"构建整个模型\n",
    "        分别构建\n",
    "        编码器（encoder）\n",
    "        解码器（decoder）\n",
    "        优化器（只在训练时构建，optimizer）\n",
    "        \"\"\"\n",
    "        self.init_placeholders()\n",
    "        encoder_outputs, encoder_state = self.build_encoder()\n",
    "        self.build_decoder(encoder_outputs, encoder_state)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            self.init_optimizer()\n",
    "\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "    def init_placeholders(self):#init_placeholders 初始化一些tensorflow的变量占位符\n",
    "        \"\"\"初始化训练、预测所需的变量\n",
    "        \"\"\"\n",
    "\n",
    "        self.add_loss = tf.placeholder(\n",
    "            dtype=tf.float32,\n",
    "            name='add_loss'\n",
    "        )\n",
    "\n",
    "        # 编码器输入，shape=(batch_size, time_step)\n",
    "        # 有 batch_size 句话，每句话是最大长度为 time_step 的 index 表示\n",
    "        self.encoder_inputs = tf.placeholder(\n",
    "            dtype=tf.int32,\n",
    "            shape=(self.batch_size, None),\n",
    "            name='encoder_inputs'\n",
    "        )\n",
    "\n",
    "        # 编码器长度输入，shape=(batch_size, 1)\n",
    "        # 指的是 batch_size 句话每句话的长度\n",
    "        self.encoder_inputs_length = tf.placeholder(\n",
    "            dtype=tf.int32,\n",
    "            shape=(self.batch_size,),#，后不加东西，加了的话是张量32*1，不加的话只表示长度32的向量\n",
    "            name='encoder_inputs_length'\n",
    "        )\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            # 训练模式\n",
    "\n",
    "            # 解码器输入，shape=(batch_size, time_step)\n",
    "            # 注意，会默认里面已经在每句结尾包含 <EOS>\n",
    "            self.decoder_inputs = tf.placeholder(\n",
    "                dtype=tf.int32,\n",
    "                shape=(self.batch_size, None),\n",
    "                name='decoder_inputs'\n",
    "            )\n",
    "\n",
    "            # 解码器输入的reward，用于强化学习训练，shape=(batch_size, 1)\n",
    "            self.rewards = tf.placeholder(\n",
    "                dtype=tf.float32,\n",
    "                shape=(self.batch_size, 1),#每多少步进行一次rewards\n",
    "                name='rewards'\n",
    "            )\n",
    "\n",
    "            # 解码器长度输入，shape=(batch_size,)\n",
    "            self.decoder_inputs_length = tf.placeholder(\n",
    "                dtype=tf.int32,\n",
    "                shape=(self.batch_size,),\n",
    "                name='decoder_inputs_length'\n",
    "            )\n",
    "            \n",
    "            #每个句子开始前加一个开始符号\n",
    "            self.decoder_start_token = tf.ones(\n",
    "                shape=(self.batch_size, 1),\n",
    "                dtype=tf.int32\n",
    "            ) * WordSequence.START\n",
    "\n",
    "            # 实际训练的解码器输入，实际上是 start_token + decoder_inputs\n",
    "            self.decoder_inputs_train = tf.concat([\n",
    "                self.decoder_start_token,\n",
    "                self.decoder_inputs\n",
    "            ], axis=1)\n",
    "\n",
    "\n",
    "    def build_single_cell(self, n_hidden, use_residual):#build_single_cell\n",
    "        \"\"\"构建一个单独的rnn cell\n",
    "        Args:\n",
    "            n_hidden: 隐藏层神经元数量\n",
    "            use_residual: 是否使用residual wrapper\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cell_type == 'gru':\n",
    "            cell_type = GRUCell\n",
    "        else:\n",
    "            cell_type = LSTMCell\n",
    "\n",
    "        cell = cell_type(n_hidden)\n",
    "\n",
    "        if self.use_dropout:\n",
    "            cell = DropoutWrapper(\n",
    "                cell,\n",
    "                dtype=tf.float32,\n",
    "                output_keep_prob=self.keep_prob_placeholder,\n",
    "                seed=self.seed\n",
    "            )\n",
    "\n",
    "        if use_residual:\n",
    "            cell = ResidualWrapper(cell)#残差网络封装API\n",
    "\n",
    "        return cell\n",
    "\n",
    "    def build_encoder_cell(self):#build_encoder_cell\n",
    "        \"\"\"构建一个单独的编码器cell\n",
    "        \"\"\"\n",
    "        return MultiRNNCell([\n",
    "            self.build_single_cell(\n",
    "                self.hidden_units,\n",
    "                use_residual=self.use_residual\n",
    "            )\n",
    "            for _ in range(self.depth)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def feed_embedding(self, sess, encoder=None, decoder=None):\n",
    "        \"\"\"加载预训练好的embedding\n",
    "        \"\"\"\n",
    "        assert self.pretrained_embedding, \\\n",
    "            '必须开启pretrained_embedding才能使用feed_embedding'\n",
    "        assert encoder is not None or decoder is not None, \\\n",
    "            'encoder 和 decoder 至少得输入一个！'\n",
    "\n",
    "        if encoder is not None:\n",
    "            sess.run(self.encoder_embeddings_init,\n",
    "                     {self.encoder_embeddings_placeholder: encoder})\n",
    "\n",
    "        if decoder is not None:\n",
    "            sess.run(self.decoder_embeddings_init,\n",
    "                     {self.decoder_embeddings_placeholder: decoder})\n",
    "\n",
    "\n",
    "    def build_encoder(self):\n",
    "        \"\"\"构建编码器\n",
    "        \"\"\"\n",
    "        # print(\"构建编码器\")\n",
    "        with tf.variable_scope('encoder'):\n",
    "            # 构建 encoder_cell\n",
    "            encoder_cell = self.build_encoder_cell()\n",
    "\n",
    "            # 编码器的embedding\n",
    "            with tf.device(_get_embed_device(self.input_vocab_size)):#决定GPU还是CPU\n",
    "\n",
    "                # 加载训练好的embedding\n",
    "                if self.pretrained_embedding:\n",
    "\n",
    "                    self.encoder_embeddings = tf.Variable(\n",
    "                        tf.constant(\n",
    "                            0.0,\n",
    "                            shape=(self.input_vocab_size, self.embedding_size)\n",
    "                        ),\n",
    "                        trainable=True,\n",
    "                        name='embeddings'\n",
    "                    )\n",
    "                    self.encoder_embeddings_placeholder = tf.placeholder(\n",
    "                        tf.float32,\n",
    "                        (self.input_vocab_size, self.embedding_size)\n",
    "                    )\n",
    "                    self.encoder_embeddings_init = self.encoder_embeddings.assign(self.encoder_embeddings_placeholder)#assign赋值\n",
    "\n",
    "                else:#相当于定义一个embedding映射\n",
    "                    self.encoder_embeddings = tf.get_variable(\n",
    "                        name='embedding',\n",
    "                        shape=(self.input_vocab_size, self.embedding_size),\n",
    "                        initializer=self.initializer,\n",
    "                        dtype=tf.float32\n",
    "                    )\n",
    "\n",
    "            #对输入变量进行embedding\n",
    "            # embedded之后的输入 shape = (batch_size, time_step, embedding_size)\n",
    "            self.encoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "                params=self.encoder_embeddings,\n",
    "                ids=self.encoder_inputs\n",
    "            )\n",
    "\n",
    "            if self.use_residual:\n",
    "                self.encoder_inputs_embedded = \\\n",
    "                    layers.dense(self.encoder_inputs_embedded,\n",
    "                                 self.hidden_units,\n",
    "                                 use_bias=False,\n",
    "                                 name='encoder_residual_projection')\n",
    "\n",
    "\n",
    "            inputs = self.encoder_inputs_embedded\n",
    "            if self.time_major:\n",
    "                inputs = tf.transpose(inputs, (1, 0, 2))\n",
    "\n",
    "            if not self.bidirectional:\n",
    "                # 单向 RNN\n",
    "                (encoder_outputs,encoder_state) = tf.nn.dynamic_rnn(\n",
    "                                                            cell=encoder_cell,\n",
    "                                                            inputs=inputs,\n",
    "                                                            sequence_length=self.encoder_inputs_length,\n",
    "                                                            dtype=tf.float32,\n",
    "                                                            time_major=self.time_major,\n",
    "                                                            parallel_iterations=self.parallel_iterations,\n",
    "                                                            swap_memory=True#是否交换内存\n",
    "                )\n",
    "            else:\n",
    "                # 双向 RNN 比较麻烦\n",
    "                encoder_cell_bw = self.build_encoder_cell()\n",
    "                (\n",
    "                    (encoder_fw_outputs, encoder_bw_outputs),\n",
    "                    (encoder_fw_state, encoder_bw_state)\n",
    "                ) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                    cell_fw=encoder_cell,\n",
    "                    cell_bw=encoder_cell_bw,\n",
    "                    inputs=inputs,\n",
    "                    sequence_length=self.encoder_inputs_length,\n",
    "                    dtype=tf.float32,\n",
    "                    time_major=self.time_major,\n",
    "                    parallel_iterations=self.parallel_iterations,\n",
    "                    swap_memory=True\n",
    "                )\n",
    "\n",
    "                # 首先合并两个方向 RNN 的输出\n",
    "                encoder_outputs = tf.concat(\n",
    "                    (encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "                #再合并两个方向RNN的状态\n",
    "                encoder_state = []\n",
    "                for i in range(self.depth):\n",
    "                    encoder_state.append(encoder_fw_state[i])\n",
    "                    encoder_state.append(encoder_bw_state[i])\n",
    "                encoder_state = tuple(encoder_state)\n",
    "\n",
    "            return encoder_outputs, encoder_state\n",
    "\n",
    "\n",
    "    def build_decoder_cell(self, encoder_outputs, encoder_state):\n",
    "        \"\"\"构建解码器cell\"\"\"\n",
    "\n",
    "        encoder_inputs_length = self.encoder_inputs_length\n",
    "        batch_size = self.batch_size\n",
    "\n",
    "        if self.bidirectional:\n",
    "            encoder_state = encoder_state[-self.depth:]\n",
    "\n",
    "        if self.time_major:\n",
    "            encoder_outputs = tf.transpose(encoder_outputs, (1, 0, 2))\n",
    "\n",
    "        # 使用 BeamSearchDecoder 的时候，必须根据 beam_width 来成倍的扩大一些变量\n",
    "\n",
    "        if self.use_beamsearch_decode:#beamsearch一种传统算法，广度优先遍历搜索查找\n",
    "            encoder_outputs = seq2seq.tile_batch(encoder_outputs, multiplier=self.beam_width)#tile_batch扩展成多份\n",
    "            encoder_state = seq2seq.tile_batch(encoder_state, multiplier=self.beam_width)\n",
    "            encoder_inputs_length = seq2seq.tile_batch(self.encoder_inputs_length, multiplier=self.beam_width)\n",
    "            # 如果使用了 beamsearch 那么输入应该是 beam_width 倍于 batch_size 的\n",
    "            batch_size *= self.beam_width\n",
    "\n",
    "        # 下面是两种不同的 Attention 机制\n",
    "        if self.attention_type.lower() == 'luong':\n",
    "            # 'Luong' style attention: https://arxiv.org/abs/1508.04025\n",
    "            self.attention_mechanism = LuongAttention(\n",
    "                num_units=self.hidden_units,\n",
    "                memory=encoder_outputs,\n",
    "                memory_sequence_length=encoder_inputs_length\n",
    "            )\n",
    "        else: # Default Bahdanau\n",
    "            # 'Bahdanau' style attention: https://arxiv.org/abs/1409.0473\n",
    "            self.attention_mechanism = BahdanauAttention(\n",
    "                num_units=self.hidden_units,\n",
    "                memory=encoder_outputs,\n",
    "                memory_sequence_length=encoder_inputs_length\n",
    "            )\n",
    "\n",
    "        # Building decoder_cell\n",
    "        cell = MultiRNNCell([\n",
    "            self.build_single_cell(\n",
    "                self.hidden_units,\n",
    "                use_residual=self.use_residual\n",
    "            )\n",
    "            for _ in range(self.depth)\n",
    "        ])\n",
    "\n",
    "        # 在非训练（预测）模式，并且没开启 beamsearch 的时候，打开 attention 历史信息\n",
    "        alignment_history = (\n",
    "            self.mode != 'train' and not self.use_beamsearch_decode\n",
    "        )\n",
    "\n",
    "        def cell_input_fn(inputs, attention):\n",
    "            \"\"\"根据attn_input_feeding属性来判断是否在attention计算前进行一次投影计算\n",
    "            \"\"\"\n",
    "            if not self.use_residual:\n",
    "                return array_ops.concat([inputs, attention], -1)\n",
    "\n",
    "            attn_projection = layers.Dense(self.hidden_units,\n",
    "                                           dtype=tf.float32,\n",
    "                                           use_bias=False,\n",
    "                                           name='attention_cell_input_fn')\n",
    "            return attn_projection(array_ops.concat([inputs, attention], -1))\n",
    "\n",
    "        cell = AttentionWrapper(\n",
    "            cell=cell,\n",
    "            attention_mechanism=self.attention_mechanism,\n",
    "            attention_layer_size=self.hidden_units,\n",
    "            alignment_history=alignment_history,\n",
    "            cell_input_fn=cell_input_fn,\n",
    "            name='Attention_Wrapper')\n",
    "\n",
    "        # 空状态\n",
    "        decoder_initial_state = cell.zero_state(\n",
    "            batch_size, tf.float32)\n",
    "\n",
    "        # 传递encoder状态\n",
    "        decoder_initial_state = decoder_initial_state.clone(\n",
    "            cell_state=encoder_state)\n",
    "\n",
    "        return cell, decoder_initial_state\n",
    "\n",
    "\n",
    "    def build_decoder(self, encoder_outputs, encoder_state):\n",
    "        \"\"\"构建解码器\n",
    "        \"\"\"\n",
    "        with tf.variable_scope('decoder') as decoder_scope:\n",
    "            (\n",
    "                self.decoder_cell,\n",
    "                self.decoder_initial_state\n",
    "            ) = self.build_decoder_cell(encoder_outputs, encoder_state)\n",
    "\n",
    "            # 解码器embedding\n",
    "            with tf.device(_get_embed_device(self.target_vocab_size)):\n",
    "                if self.share_embedding:\n",
    "                    self.decoder_embeddings = self.encoder_embeddings\n",
    "                    \n",
    "                elif self.pretrained_embedding:\n",
    "                    self.decoder_embeddings = tf.Variable(\n",
    "                        tf.constant(\n",
    "                            0.0,\n",
    "                            shape=(self.target_vocab_size,\n",
    "                                   self.embedding_size)\n",
    "                        ),\n",
    "                        trainable=True,\n",
    "                        name='embeddings'\n",
    "                    )\n",
    "                    self.decoder_embeddings_placeholder = tf.placeholder(\n",
    "                        tf.float32,\n",
    "                        (self.target_vocab_size, self.embedding_size)\n",
    "                    )\n",
    "                    self.decoder_embeddings_init = \\\n",
    "                        self.decoder_embeddings.assign(\n",
    "                            self.decoder_embeddings_placeholder)\n",
    "                    \n",
    "                else:\n",
    "                    self.decoder_embeddings = tf.get_variable(\n",
    "                        name='embeddings',\n",
    "                        shape=(self.target_vocab_size, self.embedding_size),\n",
    "                        initializer=self.initializer,\n",
    "                        dtype=tf.float32\n",
    "                    )\n",
    "                    \n",
    "            #输出全连接对应词表\n",
    "            self.decoder_output_projection = layers.Dense(\n",
    "                self.target_vocab_size,\n",
    "                dtype=tf.float32,\n",
    "                use_bias=False,\n",
    "                name='decoder_output_projection'\n",
    "            )\n",
    "\n",
    "            #训练模式\n",
    "            if self.mode == 'train':\n",
    "                self.decoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "                    params=self.decoder_embeddings,\n",
    "                    ids=self.decoder_inputs_train\n",
    "                )\n",
    "                inputs = self.decoder_inputs_embedded\n",
    "\n",
    "                if self.time_major:\n",
    "                    inputs = tf.transpose(inputs, (1, 0, 2))\n",
    "\n",
    "                #帮助feed参数\n",
    "                training_helper = seq2seq.TrainingHelper(\n",
    "                    inputs=inputs,\n",
    "                    sequence_length=self.decoder_inputs_length,\n",
    "                    time_major=self.time_major,\n",
    "                    name='training_helper'\n",
    "                )\n",
    "\n",
    "                # 训练的时候不在这里应用 output_layer\n",
    "                # 因为这里会每个 time_step 的进行 output_layer 的投影计算，比较慢\n",
    "                # 注意这个trick要成功必须设置 dynamic_decode 的 scope 参数\n",
    "                training_decoder = seq2seq.BasicDecoder(\n",
    "                    cell=self.decoder_cell,\n",
    "                    helper=training_helper,\n",
    "                    initial_state=self.decoder_initial_state,\n",
    "                )\n",
    "\n",
    "                # Maximum decoder time_steps in current batch\n",
    "                max_decoder_length = tf.reduce_max(\n",
    "                    self.decoder_inputs_length\n",
    "                )\n",
    "\n",
    "\n",
    "                (\n",
    "                    outputs,\n",
    "                    self.final_state, # contain attention\n",
    "                    _ # self.final_sequence_lengths\n",
    "                ) = seq2seq.dynamic_decode(\n",
    "                    decoder=training_decoder,\n",
    "                    output_time_major=self.time_major,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=max_decoder_length,\n",
    "                    parallel_iterations=self.parallel_iterations,\n",
    "                    swap_memory=True,\n",
    "                    scope=decoder_scope\n",
    "                )\n",
    "\n",
    "                #让运行速度更快\n",
    "                self.decoder_logits_train = self.decoder_output_projection(\n",
    "                    outputs.rnn_output\n",
    "                )\n",
    "\n",
    "                #做验证填充\n",
    "                # masks: masking for valid and padded time steps,\n",
    "                # [batch_size, max_time_step + 1]\n",
    "                self.masks = tf.sequence_mask(\n",
    "                    lengths=self.decoder_inputs_length,\n",
    "                    maxlen=max_decoder_length,\n",
    "                    dtype=tf.float32, name='masks'\n",
    "                )\n",
    "\n",
    "                decoder_logits_train = self.decoder_logits_train\n",
    "                if self.time_major:\n",
    "                    decoder_logits_train = tf.transpose(decoder_logits_train,\n",
    "                                                        (1, 0, 2))\n",
    "\n",
    "                #decoder_pred_train即为预测值\n",
    "                self.decoder_pred_train = tf.argmax(\n",
    "                    decoder_logits_train, axis=-1,\n",
    "                    name='decoder_pred_train')\n",
    "\n",
    "                # 下面的一些变量用于特殊的学习训练\n",
    "                # 自定义rewards，其实我这里是修改了masks\n",
    "                # train_entropy = cross entropy\n",
    "                self.train_entropy = \\\n",
    "                    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                        labels=self.decoder_inputs,\n",
    "                        logits=decoder_logits_train)\n",
    "\n",
    "                self.masks_rewards = self.masks * self.rewards\n",
    "\n",
    "                self.loss_rewards = seq2seq.sequence_loss(\n",
    "                    logits=decoder_logits_train,\n",
    "                    targets=self.decoder_inputs,\n",
    "                    weights=self.masks_rewards,\n",
    "                    average_across_timesteps=True,\n",
    "                    average_across_batch=True,\n",
    "                )\n",
    "\n",
    "                self.loss = seq2seq.sequence_loss(\n",
    "                    logits=decoder_logits_train,\n",
    "                    targets=self.decoder_inputs,\n",
    "                    weights=self.masks,\n",
    "                    average_across_timesteps=True,\n",
    "                    average_across_batch=True,\n",
    "                )\n",
    "\n",
    "                self.loss_add = self.loss + self.add_loss\n",
    "\n",
    "            elif self.mode == 'decode':\n",
    "                # 预测模式，非训练\n",
    "\n",
    "                start_tokens = tf.tile(#给batch_size句话每句话加上开头\n",
    "                    [WordSequence.START],\n",
    "                    [self.batch_size]\n",
    "                )\n",
    "                end_token = WordSequence.END\n",
    "\n",
    "                def embed_and_input_proj(inputs):\n",
    "                    \"\"\"输入层的投影层wrapper\n",
    "                    \"\"\"\n",
    "                    return tf.nn.embedding_lookup(\n",
    "                        self.decoder_embeddings,\n",
    "                        inputs\n",
    "                    )\n",
    "\n",
    "                if not self.use_beamsearch_decode:\n",
    "                    # Helper to feed inputs for greedy decoding:\n",
    "                    # uses the argmax of the output\n",
    "                    decoding_helper = seq2seq.GreedyEmbeddingHelper(\n",
    "                        start_tokens=start_tokens,\n",
    "                        end_token=end_token,\n",
    "                        embedding=embed_and_input_proj\n",
    "                    )\n",
    "                    # Basic decoder performs greedy decoding at each time step\n",
    "                    # print(\"building greedy decoder..\")\n",
    "                    inference_decoder = seq2seq.BasicDecoder(\n",
    "                        cell=self.decoder_cell,\n",
    "                        helper=decoding_helper,\n",
    "                        initial_state=self.decoder_initial_state,\n",
    "                        output_layer=self.decoder_output_projection\n",
    "                    )\n",
    "                else:\n",
    "                    # Beamsearch is used to approximately\n",
    "                    # find the most likely translation\n",
    "                    # print(\"building beamsearch decoder..\")\n",
    "                    inference_decoder = BeamSearchDecoder(#inference_decoder 要生成答案的encoder\n",
    "                        cell=self.decoder_cell,\n",
    "                        embedding=embed_and_input_proj,\n",
    "                        start_tokens=start_tokens,\n",
    "                        end_token=end_token,\n",
    "                        initial_state=self.decoder_initial_state,\n",
    "                        beam_width=self.beam_width,\n",
    "                        output_layer=self.decoder_output_projection,\n",
    "                    )\n",
    "\n",
    "                if self.max_decode_step is not None:\n",
    "                    max_decode_step = self.max_decode_step\n",
    "                else:\n",
    "                    # 默认 4 倍输入长度的输出解码\n",
    "                    max_decode_step = tf.round(tf.reduce_max(\n",
    "                        self.encoder_inputs_length) * 4)\n",
    "\n",
    "                (\n",
    "                    self.decoder_outputs_decode,\n",
    "                    self.final_state,\n",
    "                    _ # self.decoder_outputs_length_decode\n",
    "                ) = (seq2seq.dynamic_decode(\n",
    "                    decoder=inference_decoder,\n",
    "                    output_time_major=self.time_major,\n",
    "                    # impute_finished=True,\t# error occurs\n",
    "                    maximum_iterations=max_decode_step,\n",
    "                    parallel_iterations=self.parallel_iterations,\n",
    "                    swap_memory=True,\n",
    "                    scope=decoder_scope\n",
    "                ))\n",
    "\n",
    "                if not self.use_beamsearch_decode:\n",
    "\n",
    "                    dod = self.decoder_outputs_decode\n",
    "                    self.decoder_pred_decode = dod.sample_id\n",
    "\n",
    "                    if self.time_major:\n",
    "                        self.decoder_pred_decode = tf.transpose(\n",
    "                            self.decoder_pred_decode, (1, 0))\n",
    "\n",
    "                else:\n",
    "                    self.decoder_pred_decode = \\\n",
    "                        self.decoder_outputs_decode.predicted_ids\n",
    "\n",
    "                    if self.time_major:\n",
    "                        self.decoder_pred_decode = tf.transpose(\n",
    "                            self.decoder_pred_decode, (1, 0, 2))\n",
    "\n",
    "                    self.decoder_pred_decode = tf.transpose(\n",
    "                        self.decoder_pred_decode,\n",
    "                        perm=[0, 2, 1])\n",
    "                    dod = self.decoder_outputs_decode\n",
    "                    self.beam_prob = dod.beam_search_decoder_output.scores\n",
    "\n",
    "\n",
    "    def save(self, sess, save_path='model.ckpt'):#有两种保存模型的放大 ckpt：训练模型后的保存，保存所有参数，文件较大，用来模型恢复加载\n",
    "        \"\"\"保存模型\"\"\"                          #pb:用来模型最后的线上部署，芝用TensorFlow的serving进行模型发布，一般发布成grpc形式的接口\n",
    "        self.saver.save(sess, save_path=save_path)\n",
    "\n",
    "\n",
    "    def load(self, sess, save_path='model.ckpt'):\n",
    "        \"\"\"读取模型\"\"\"\n",
    "        print('try load model from', save_path)\n",
    "        self.saver.restore(sess, save_path)\n",
    "\n",
    "\n",
    "    def init_optimizer(self):\n",
    "        \"\"\"初始化优化器\n",
    "        支持的方法有 sgd, adadelta, adam, rmsprop, momentum\n",
    "        \"\"\"\n",
    "\n",
    "        # 学习率下降算法\n",
    "        learning_rate = tf.train.polynomial_decay(\n",
    "            self.learning_rate,\n",
    "            self.global_step,\n",
    "            self.decay_steps,\n",
    "            self.min_learning_rate,\n",
    "            power=0.5\n",
    "        )\n",
    "        self.current_learning_rate = learning_rate\n",
    "\n",
    "        # 设置优化器,合法的优化器如下\n",
    "        # 'adadelta', 'adam', 'rmsprop', 'momentum', 'sgd'就是\n",
    "        trainable_params = tf.trainable_variables()\n",
    "        if self.optimizer.lower() == 'adadelta':\n",
    "            self.opt = tf.train.AdadeltaOptimizer(\n",
    "                learning_rate=learning_rate)\n",
    "        elif self.optimizer.lower() == 'adam':\n",
    "            self.opt = tf.train.AdamOptimizer(\n",
    "                learning_rate=learning_rate)\n",
    "        elif self.optimizer.lower() == 'rmsprop':\n",
    "            self.opt = tf.train.RMSPropOptimizer(\n",
    "                learning_rate=learning_rate)\n",
    "        elif self.optimizer.lower() == 'momentum':\n",
    "            self.opt = tf.train.MomentumOptimizer(\n",
    "                learning_rate=learning_rate, momentum=0.9)\n",
    "        elif self.optimizer.lower() == 'sgd':\n",
    "            self.opt = tf.train.GradientDescentOptimizer(\n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "        gradients = tf.gradients(self.loss, trainable_params)\n",
    "        # Clip gradients by a given maximum_gradient_norm\n",
    "        clip_gradients, _ = tf.clip_by_global_norm(#梯度裁剪\n",
    "            gradients, self.max_gradient_norm)\n",
    "        # Update the model\n",
    "        self.updates = self.opt.apply_gradients(#应用梯度\n",
    "            zip(clip_gradients, trainable_params),\n",
    "            global_step=self.global_step)\n",
    "\n",
    "        # 使用包括rewards的loss进行更新\n",
    "        # 是特殊学习的一部分\n",
    "        gradients = tf.gradients(self.loss_rewards, trainable_params)\n",
    "        clip_gradients, _ = tf.clip_by_global_norm(\n",
    "            gradients, self.max_gradient_norm)\n",
    "        self.updates_rewards = self.opt.apply_gradients(\n",
    "            zip(clip_gradients, trainable_params),\n",
    "            global_step=self.global_step)\n",
    "\n",
    "        # 添加 self.loss_add 的 update\n",
    "        gradients = tf.gradients(self.loss_add, trainable_params)\n",
    "        clip_gradients, _ = tf.clip_by_global_norm(\n",
    "            gradients, self.max_gradient_norm)\n",
    "        self.updates_add = self.opt.apply_gradients(\n",
    "            zip(clip_gradients, trainable_params),\n",
    "            global_step=self.global_step)\n",
    "\n",
    "\n",
    "    def check_feeds(self, encoder_inputs, encoder_inputs_length,\n",
    "                    decoder_inputs, decoder_inputs_length, decode):\n",
    "        \"\"\"检查输入变量，并返回input_feed\n",
    "\n",
    "        我们首先会把数据编码，例如把“你好吗”，编码为[0, 1, 2]\n",
    "        多个句子组成一个batch，共同训练，例如一个batch_size=2，那么训练矩阵就可能是\n",
    "        encoder_inputs = [\n",
    "            [0, 1, 2, 3],\n",
    "            [4, 5, 6, 7]\n",
    "        ]\n",
    "        它所代表的可能是：[['我', '是', '帅', '哥'], ['你', '好', '啊', '</s>']]\n",
    "        注意第一句的真实长度是 4，第二句只有 3（最后的</s>是一个填充数据）\n",
    "\n",
    "        那么：\n",
    "        encoder_inputs_length = [4, 3]\n",
    "        来代表输入整个batch的真实长度\n",
    "        注意，为了符合算法要求，每个batch的句子必须是长度降序的，也就是说你输入一个\n",
    "        encoder_inputs_length = [1, 10] 这样是错误的，必须在输入前排序到\n",
    "        encoder_inputs_length = [10, 1] 这样才行\n",
    "\n",
    "        decoder_inputs 和 decoder_inputs_length 所代表的含义差不多\n",
    "\n",
    "        Args:\n",
    "            encoder_inputs:\n",
    "                一个整形二维矩阵 [batch_size, max_source_time_steps]\n",
    "            encoder_inputs_length:\n",
    "                一个整形向量 [batch_size]\n",
    "                每个维度是encoder句子的真实长度\n",
    "            decoder_inputs:\n",
    "                一个整形矩阵 [batch_size, max_target_time_steps]\n",
    "            decoder_inputs_length:\n",
    "                一个整形向量 [batch_size]\n",
    "                每个维度是decoder句子的真实长度\n",
    "            decode: 用来指示正在训练模式(decode=False)还是预测模式(decode=True)\n",
    "        Returns:\n",
    "            tensorflow所操作需要的input_feed，包括\n",
    "            encoder_inputs, encoder_inputs_length,\n",
    "            decoder_inputs, decoder_inputs_length\n",
    "        \"\"\"\n",
    "\n",
    "        input_batch_size = encoder_inputs.shape[0]\n",
    "        if input_batch_size != encoder_inputs_length.shape[0]:\n",
    "            raise ValueError(\n",
    "                \"encoder_inputs和encoder_inputs_length的第一维度必须一致 \"\n",
    "                \"这一维度是batch_size, %d != %d\" % (\n",
    "                    input_batch_size, encoder_inputs_length.shape[0]))\n",
    "\n",
    "        if not decode:\n",
    "            target_batch_size = decoder_inputs.shape[0]\n",
    "            if target_batch_size != input_batch_size:\n",
    "                raise ValueError(\n",
    "                    \"encoder_inputs和decoder_inputs的第一维度必须一致 \"\n",
    "                    \"这一维度是batch_size, %d != %d\" % (\n",
    "                        input_batch_size, target_batch_size))\n",
    "            if target_batch_size != decoder_inputs_length.shape[0]:\n",
    "                raise ValueError(\n",
    "                    \"edeoder_inputs和decoder_inputs_length的第一维度必须一致 \"\n",
    "                    \"这一维度是batch_size, %d != %d\" % (\n",
    "                        target_batch_size, decoder_inputs_length.shape[0]))\n",
    "\n",
    "        input_feed = {}\n",
    "\n",
    "        input_feed[self.encoder_inputs.name] = encoder_inputs\n",
    "        input_feed[self.encoder_inputs_length.name] = encoder_inputs_length\n",
    "\n",
    "        if not decode:\n",
    "            input_feed[self.decoder_inputs.name] = decoder_inputs\n",
    "            input_feed[self.decoder_inputs_length.name] = decoder_inputs_length\n",
    "\n",
    "        return input_feed\n",
    "\n",
    "\n",
    "    def train(self, sess, encoder_inputs, encoder_inputs_length,\n",
    "              decoder_inputs, decoder_inputs_length,\n",
    "              rewards=None, return_lr=False,\n",
    "              loss_only=False, add_loss=None):\n",
    "        \"\"\"训练模型\"\"\"\n",
    "\n",
    "        # 输入\n",
    "        input_feed = self.check_feeds(\n",
    "            encoder_inputs, encoder_inputs_length,\n",
    "            decoder_inputs, decoder_inputs_length,\n",
    "            False\n",
    "        )\n",
    "\n",
    "        # 设置 dropout\n",
    "        input_feed[self.keep_prob_placeholder.name] = self.keep_prob\n",
    "\n",
    "        if loss_only:\n",
    "            # 输出\n",
    "            return sess.run(self.loss, input_feed)\n",
    "\n",
    "        if add_loss is not None:\n",
    "            input_feed[self.add_loss.name] = add_loss\n",
    "            output_feed = [\n",
    "                self.updates_add, self.loss_add,\n",
    "                self.current_learning_rate]\n",
    "            _, cost, lr = sess.run(output_feed, input_feed)\n",
    "\n",
    "            if return_lr:\n",
    "                return cost, lr\n",
    "\n",
    "            return cost\n",
    "\n",
    "        if rewards is not None:\n",
    "            input_feed[self.rewards.name] = rewards\n",
    "            output_feed = [\n",
    "                self.updates_rewards, self.loss_rewards,\n",
    "                self.current_learning_rate]\n",
    "            _, cost, lr = sess.run(output_feed, input_feed)\n",
    "\n",
    "            if return_lr:\n",
    "                return cost, lr\n",
    "            return cost\n",
    "\n",
    "        output_feed = [\n",
    "            self.updates, self.loss,\n",
    "            self.current_learning_rate]\n",
    "        _, cost, lr = sess.run(output_feed, input_feed)\n",
    "\n",
    "        if return_lr:\n",
    "            return cost, lr\n",
    "\n",
    "        return cost\n",
    "\n",
    "\n",
    "    def get_encoder_embedding(self, sess, encoder_inputs):\n",
    "        \"\"\"获取经过embedding的encoder_inputs\"\"\"\n",
    "        input_feed = {\n",
    "            self.encoder_inputs.name: encoder_inputs\n",
    "        }\n",
    "        emb = sess.run(self.encoder_inputs_embedded, input_feed)\n",
    "        return emb\n",
    "\n",
    "\n",
    "    def entropy(self, sess, encoder_inputs, encoder_inputs_length,\n",
    "                decoder_inputs, decoder_inputs_length):\n",
    "        \"\"\"获取针对一组输入输出的entropy\n",
    "        相当于在计算P(target|source)\n",
    "        \"\"\"\n",
    "        input_feed = self.check_feeds(\n",
    "            encoder_inputs, encoder_inputs_length,\n",
    "            decoder_inputs, decoder_inputs_length,\n",
    "            False\n",
    "        )\n",
    "        input_feed[self.keep_prob_placeholder.name] = 1.0\n",
    "        output_feed = [self.train_entropy, self.decoder_pred_train]\n",
    "        entropy, logits = sess.run(output_feed, input_feed)\n",
    "        return entropy, logits\n",
    "\n",
    "\n",
    "    def predict(self, sess,\n",
    "                encoder_inputs,\n",
    "                encoder_inputs_length,\n",
    "                attention=False):\n",
    "        \"\"\"预测输出\"\"\"\n",
    "\n",
    "        # 输入\n",
    "        input_feed = self.check_feeds(encoder_inputs,\n",
    "                                      encoder_inputs_length, None, None, True)\n",
    "\n",
    "        input_feed[self.keep_prob_placeholder.name] = 1.0\n",
    "\n",
    "        # Attention 输出\n",
    "        if attention:\n",
    "\n",
    "            assert not self.use_beamsearch_decode, \\\n",
    "                'Attention 模式不能打开 BeamSearch'\n",
    "\n",
    "            pred, atten = sess.run([\n",
    "                self.decoder_pred_decode,\n",
    "                self.final_state.alignment_history.stack()\n",
    "            ], input_feed)\n",
    "\n",
    "            return pred, atten\n",
    "\n",
    "        # BeamSearch 模式输出\n",
    "        if self.use_beamsearch_decode:\n",
    "            pred, beam_prob = sess.run([\n",
    "                self.decoder_pred_decode, self.beam_prob\n",
    "            ], input_feed)\n",
    "            beam_prob = np.mean(beam_prob, axis=1)\n",
    "\n",
    "            pred = pred[0]\n",
    "            return pred\n",
    "\n",
    "        # 普通（Greedy）模式输出\n",
    "        pred, = sess.run([\n",
    "            self.decoder_pred_decode\n",
    "        ], input_feed)\n",
    "\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
